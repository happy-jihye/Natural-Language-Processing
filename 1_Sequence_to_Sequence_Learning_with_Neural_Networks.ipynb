{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 - Sequence to Sequence Learning with Neural Networks",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIWPJE4O8P+37aotDt2DxU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/happy-jihye/Natural-Language-Processing/blob/main/1_Sequence_to_Sequence_Learning_with_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsCHC88ibsh1"
      },
      "source": [
        "# 1 - Sequence to Sequence Learning with Neural Networks\n",
        "\n",
        "- Seq2Seq ì‹œë¦¬ì¦ˆì—ì„œëŠ” Pytorchì™€ torch textë¥¼ ì´ìš©í•˜ì—¬ í•˜ë‚˜ì˜ `seq`ë¥¼ ë‹¤ë¥¸ `seq`ë¡œ ë°”ê¾¸ëŠ” ë¨¸ì‹  ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬ì¶•í•  ì˜ˆì •ì…ë‹ˆë‹¤. \n",
        "- tutorial-1ì—ì„œëŠ” `ë…ì¼ì–´`ë¥¼ `ì˜ì–´`ë¡œ ë²ˆì—­í•˜ëŠ” translation modelì„ í•™ìŠµí•©ë‹ˆë‹¤. Seq2Seq model ëª¨ë¸ì€ ë²ˆì—­ ì™¸ì—ë„ ë‚´ìš© ìš”ì•½(Text Summarization), STT(Speech to Text)ë“±ì— ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "\n",
        "- ì´ë²ˆ ë…¸íŠ¸ë¶ì—ì„œëŠ” [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) paperì˜ ëª¨ë¸ì„ ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•  ì˜ˆì •ì…ë‹ˆë‹¤. ì´ ë…¼ë¬¸ì€ encoder-decoder modelì„ ì œì‹œí•œ ëª¨ë¸ë¡œ, ìì—°ì–´ ì²˜ë¦¬ì— ìˆì–´ êµ‰ì¥íˆ ì¤‘ìš”í•œ ë…¼ë¬¸ì´ë‹ˆ í•œë²ˆì¯¤ì€ ì½ì–´ë³´ì‹œëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤ :)\n",
        "\n",
        "> 2021/03/19 Happy-jihye ğŸŒº\n",
        "> \n",
        "> **Reference** : [pytorch-seq2seq/1 - Sequence to Sequence Learning with Neural Networks](https://github.com/bentrevett/pytorch-seq2seq)\n",
        "\n",
        "--- \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6cHb1ugpMAa"
      },
      "source": [
        "## Seq2Seq\n",
        "\n",
        "- ê°€ì¥ ì¼ë°˜ì ì¸ Seq2Seq ëª¨ë¸ì€ `encoder-decoder` ëª¨ë¸ì…ë‹ˆë‹¤. input ë¬¸ì¥ì„ RNNìœ¼ë¡œ single vectorë¡œ ì¸ì½”ë”©í•œ í›„, ì´ single vectorë¥¼ ë‹¤ì‹œ RNN ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ ë””ì½”ë”©í•©ë‹ˆë‹¤.\n",
        "- single vectorëŠ” **context vector**ë¼ê³ ë„ ë¶ˆë¦¬ë©°, ì „ì²´ ì…ë ¥ ë¬¸ì¥ì˜ ì¶”ìƒì ì¸ í‘œí˜„ìœ¼ë¡œ ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "![](/images/seq2seq1.png)\n",
        "\n",
        "**Encoder**\n",
        "- ìœ„ì˜ ì´ë¯¸ì§€ëŠ” ëŒ€í‘œì ì¸ ë²ˆì—­ ì˜ˆì œë¡œ, \"guten morgen\"ì´ë¼ëŠ” source ë¬¸ì¥ì€ ë…¸ë€ìƒ‰ì˜ `embedding layer`ë¥¼ ê±¸ì³  ì´ˆë¡ìƒ‰ì˜ `encoder`ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤. \n",
        "- `<sos>` tokenì€ *start of sequence*, <eos> tokenì€ *end of sequence*ì˜ ì•½ìë¡œ ë¬¸ì¥ì˜ ì‹œì‘ê³¼ ëì„ ì•Œë¦¬ëŠ” tokenì…ë‹ˆë‹¤. \n",
        "- Encoder RNNì€ ì´ì „ time stepì˜ hidden stateì™€ í˜„ì¬ time stepì˜ ebeddingê°’ì„ inputìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤. ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
        "\n",
        "  $h_t = \\text{EncoderRNN}(e(x_t), h_{t-1})$\n",
        "  - ì—¬ê¸°ì„œ input sentenceëŠ” $X = \\{x_1, x_2, ..., x_T\\}$ë¡œ í‘œí˜„ë˜ë©°, $x_1$ ì€ `<sos>`, $x_2$ ëŠ” `guten`ì´ ë©ë‹ˆë‹¤. \n",
        "  - ë˜í•œ ì´ˆê¸° hidden state, $h_0$ëŠ” 0ì´ ë˜ê±°ë‚˜ í•™ìŠµëœ parameterë¡œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.\n",
        "\n",
        "- RNNë¡œëŠ” LSTM (Long Short-Term Memory)ë‚˜ GRU (Gated Recurrent Unit)ì™€ ê°™ì€ architectureë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "**context vector**\n",
        "- ìµœì¢… ë‹¨ì–´ì¸ $x_T$, `<eos>`ê°€ embedding layerë¥¼ í†µí•´ RNNì— ì „ë‹¬ë˜ë©´, ìš°ë¦¬ëŠ” ë§ˆì§€ë§‰ hidden stateì¸ $h_T$ì„ ì–»ì„ ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ context vectorë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. \n",
        "- context vectorëŠ” ì „ì²´ ë¬¸ì¥ì„ ëŒ€í‘œí•˜ë©°, $h_T = z$ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "**Decoder**\n",
        "- ì´ì œ ìš°ë¦¬ëŠ” context vectorì¸ $z$ë¥¼ output/target sentenceë¡œ ë””ì½”ë”©í•´ì•¼í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë¬¸ì¥ì˜ ì• ë’¤ì— `<sos>`ì™€ `<eos>` tokenì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "- ë””ì½”ë”© ê³¼ì •ì„ ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
        "  \n",
        "  $s_t = \\text{DecoderRNN}(d(y_t), s_{t-1})$\n",
        "\n",
        "  - ì—¬ê¸°ì„œ í˜„ì¬ ë‹¨ì–´ë¥¼ embedding, $y$í•œ ê°’ì´ $d(y_t)$ì´ë©°, context vector $z = h_T$ëŠ” ì²«ë²ˆì§¸ hidden stateì¸ $s_0$ê³¼ë„ ê°™ìŠµë‹ˆë‹¤.\n",
        "\n",
        "- ìš°ë¦¬ëŠ” decoderì˜ hidden state $s_t$ë¥¼ ë³´ë¼ìƒ‰ì˜ `Linear layer`ì— ë„£ìŒìœ¼ë¡œì¨ predictionê°’ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "  $\\hat{y}_t = f(s_t)$\n",
        "\n",
        "- ì´ë•Œ, decoderì˜ ë‹¨ì–´ëŠ” ê° time stepë‹¹ í•˜ë‚˜ì”© ì°¨ë¡€ëŒ€ë¡œ ìƒì„±ë©ë‹ˆë‹¤. decoderë¥¼ ê±°ì¹˜ë©´ì„œ ë§ì€ ë‹¨ì–´ë“¤ì´ ìƒì„±ì´ ë˜ëŠ”ë°, `<eos>` tokenì´ ì¶œë ¥ë˜ë©´ decodingì„ ë©ˆì¶¥ë‹ˆë‹¤.\n",
        "- ì˜ˆì¸¡ê°’  $\\hat{Y} = \\{ \\hat{y}_1, \\hat{y}_2, ..., \\hat{y}_T \\}$ì„ ì‹¤ì œ target senteceì˜ ê°’ $Y = \\{ y_1, y_2, ..., y_T \\}$ê³¼ ë¹„êµí•˜ì—¬ ì •í™•ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG8aw82pwUfS"
      },
      "source": [
        "## 1. Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MngZOT9T3jC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4eef786-445c-44ec-b257-d50aca5f095f"
      },
      "source": [
        "!apt install python3.7\n",
        "!pip install -U torchtext==0.6.0\n",
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3.7 is already the newest version (3.7.10-1+bionic2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "Collecting torchtext==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2MB 12.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.8.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.9.0\n",
            "    Uninstalling torchtext-0.9.0:\n",
            "      Successfully uninstalled torchtext-0.9.0\n",
            "Successfully installed sentencepiece-0.1.95 torchtext-0.6.0\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.1.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2mâœ” Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.9MB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (54.1.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.1)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp37-none-any.whl size=14907057 sha256=bc81d9c52b9ca2a652889005829b0210d8a3b6cdccfb8e475cc63f32e5ace4e3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3ledxsbu/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2mâœ” Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKucp-663qub"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL5Yr3e63rDv"
      },
      "source": [
        "### **Tokenizers**\n",
        "- tokenizersëŠ” ë¬¸ì¥ì„ ê°œë³„ tokenìœ¼ë¡œ ë³€í™˜í•´ì£¼ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "  - e.g. \"good morning!\" becomes [\"good\", \"morning\", \"!\"]\n",
        "- nlpë¥¼ ì‰½ê²Œ í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” python packageì¸ `spaCy`ë¥¼ ì´ìš©í•˜ì—¬, tokení™”ë¥¼ í•  ì˜ˆì •ì…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI8Csi-13rG4"
      },
      "source": [
        "spacy_de = spacy.load('de')\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KugnoMoE3rJz"
      },
      "source": [
        "**Reversing the order of the words**\n",
        "\n",
        "  \n",
        "ì´ ë…¼ë¬¸ì—ì„œëŠ” ë‹¨ì–´ì˜ ìˆœì„œë¥¼ ë°”ê¾¸ë©´ ìµœì í™”ê°€ ë” ì‰¬ì›Œì ¸ ì„±ëŠ¥ì´ ë” ì¢‹ì•„ì§„ë‹¤ê³  ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì´ë¥¼ ìœ„í•´ `ë…ì¼ì–´`ëŠ” tokení™”ë¥¼ í•œ í›„ ì—­ìˆœìœ¼ë¡œ listì— ì €ì¥í–ˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E-XOILd3rMt"
      },
      "source": [
        "def tokenize_de(text):\n",
        "  return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n",
        "\n",
        "def tokenize_en(text):\n",
        "  return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeGj4lbd55Al"
      },
      "source": [
        "ë‹¤ìŒìœ¼ë¡œëŠ” **Field** ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjgQFUgu5_6C"
      },
      "source": [
        "SRC = Field(tokenize= tokenize_de,\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "\n",
        "TRG = Field(tokenize= tokenize_en,\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYlgumKSZkq8"
      },
      "source": [
        "- datasetìœ¼ë¡œëŠ” [Multi30k dataset](https://github.com/multi30k/dataset)ì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ì•½ 3ë§Œê°œì˜ ì˜ì–´, ë…ì¼ì–´, í”„ë‘ìŠ¤ì–´ ë¬¸ì¥ì´ ìˆëŠ” ë°ì´í„°ì´ë©° ê° ë¬¸ì¥ë‹¹ 12ê°œì˜ ë‹¨ì–´ê°€ ìˆìŠµë‹ˆë‹¤.\n",
        "- `exts`ëŠ” sourceì™€ targetìœ¼ë¡œ ì‚¬ìš©í•  ì–¸ì–´ë¥¼ ì§€ì •í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jnnu07gTZgQz",
        "outputId": "3891aa17-5e7f-41a1-fb97-e78d1b5d0222"
      },
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts= ('.de', '.en'),\n",
        "                                                    fields = (SRC, TRG))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.21M/1.21M [00:01<00:00, 608kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46.3k/46.3k [00:00<00:00, 173kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66.2k/66.2k [00:00<00:00, 162kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DezyyLzCaOXs",
        "outputId": "05ee126a-4ba5-4877-b38f-fdb6af6e6b1a"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 29000\n",
            "Number of validation examples: 1014\n",
            "Number of testing examples: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDcZx_nNaYas"
      },
      "source": [
        "- dataë¥¼ ì¶œë ¥í•´ë³¸ ê²°ê³¼, sourceë¬¸ì¥ì€ ì—­ìˆœìœ¼ë¡œ ì €ì¥ë˜ì–´ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrjrpOA4aWVY",
        "outputId": "7164ca97-1a00-43c5-b1bf-ce0839c0a8a2"
      },
      "source": [
        "print(len(vars(train_data.examples[0])['src']))\n",
        "print(len(vars(train_data.examples[1])['src']))\n",
        "\n",
        "print(vars(train_data.examples[0]))\n",
        "print(vars(train_data.examples[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "8\n",
            "{'src': ['.', 'bÃ¼sche', 'vieler', 'nÃ¤he', 'der', 'in', 'freien', 'im', 'sind', 'mÃ¤nner', 'weiÃŸe', 'junge', 'zwei'], 'trg': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n",
            "{'src': ['.', 'antriebsradsystem', 'ein', 'bedienen', 'schutzhelmen', 'mit', 'mÃ¤nner', 'mehrere'], 'trg': ['several', 'men', 'in', 'hard', 'hats', 'are', 'operating', 'a', 'giant', 'pulley', 'system', '.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Vh7OEkal9X"
      },
      "source": [
        "### Build Vocabulary\n",
        "- `build_vocab`í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ê° tokenì„ indexingí•´ì¤ë‹ˆë‹¤. ì´ë•Œ, sourceì™€ targetì˜ vocabularyëŠ” ë‹¤ë¦…ë‹ˆë‹¤.\n",
        "- `min_freq`ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì†Œ 2ë²ˆ ì´ìƒ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ë“¤ë§Œ vocabularyì— ë„£ì–´ì£¼ì—ˆìŠµë‹ˆë‹¤. ì´ë•Œ, í•œë²ˆë§Œ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ëŠ” `<unk>` tokenìœ¼ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.\n",
        "- ì´ë•Œ, vocabularyëŠ” **training set**ì—ì„œë§Œ ë§Œë“¤ì–´ì ¸ì•¼í•©ë‹ˆë‹¤. *(validation/test setì— ëŒ€í•´ì„œëŠ” ë§Œë“¤ì–´ì§€ë©´ ì•ˆë¨!!)* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKCsid6tbl_x"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJB1I4Rmbs5h",
        "outputId": "803c6efa-c96d-41c1-982c-ba33108989f2"
      },
      "source": [
        "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source (de) vocabulary: 7855\n",
            "Unique tokens in target (en) vocabulary: 5893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH8PWXeRbxz0"
      },
      "source": [
        "### Create the iterators\n",
        "- `BucketIterator`ë¥¼ ì´ìš©í•˜ì—¬ batch sizeë³„ë¡œ tokenë“¤ì„ ë¬¶ê³ , ì–´íœ˜ë¥¼ ì½ì„ ìˆ˜ ìˆëŠ” tokenì—ì„œ indexë¡œ ë³€í™˜í•´ì¤ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmHuEKeygLnl"
      },
      "source": [
        "# for using GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4tWF2FNgTg_"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNhZ55rHJgd_",
        "outputId": "b0b119aa-41ff-4413-cafd-ed2dfed4778d"
      },
      "source": [
        "for i, batch in enumerate(train_iterator):\n",
        "    src = batch.src\n",
        "    trg = batch.trg\n",
        "\n",
        "    print(f\"ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ text í¬ê¸°: {src.shape}\")\n",
        "\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ text í¬ê¸°: torch.Size([26, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMO69_r3geyB"
      },
      "source": [
        "## Building the Seq2Seq Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROkRbTVngkFH"
      },
      "source": [
        "### Encoder\n",
        "- EncoderëŠ” 2ê°œì˜ LSTM layerë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. (ë…¼ë¬¸ì—ì„œëŠ” 4ê°œì˜ layerë¥¼ ì‚¬ìš©í–ˆì§€ë§Œ, ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” í•™ìŠµì‹œê°„ì„ ì¤„ì´ê¸° ìœ„í•´ 2ê°œì˜ layerë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.)\n",
        "- RNNì—ì„œëŠ” ì²«ë²ˆì§¸ layerì˜ hidden stateë¥¼ $h_t^1 = \\text{EncoderRNN}^1(e(x_t), h_{t-1}^1)$ë¡œ, ë‘ë²ˆì§¸ layerì˜ hidden stateë¥¼ $h_t^2 = \\text{EncoderRNN}^2(h_t^1, h_{t-1}^2)$ë¡œ í‘œí˜„í–ˆë‹¤ë©´, LSTMì€ `cell state`ì¸  $c_t$ë„ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤.\n",
        "\n",
        "![](/images/seq2seq2.png)\n",
        "\n",
        "- ë”°ë¼ì„œ LSTMì—ì„œì˜ multi-layer equationì„ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "  $(h_t^1, c_t^1) = \\text{EncoderLSTM}^1(e(x_t), (h_{t-1}^1, c_{t-1}^1))$\n",
        "  $(h_t^2, c_t^2) = \\text{EncoderLSTM}^2(h_t^1, (h_{t-1}^2, c_{t-1}^2))$\n",
        " \n",
        "- RNN architectureì— ëŒ€í•œ ì„¤ëª…ì€ [ì´ ê¸€](https://happy-jihye.github.io/nlp/2_Updated_Sentiment_Analysis/#lstm-long-short-term-memory)ì— ìì„¸íˆ ì ì–´ë†“ì•˜ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl32aWGThzhY"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hid_dim = hid_dim\n",
        "    self.n_layers = n_layers\n",
        "\n",
        "    self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "    self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, src):\n",
        "\n",
        "    # src = [src len, batch size]\n",
        "    embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "    # embedded = [src len, batch size, emb dim]\n",
        "\n",
        "    outputs, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "    # hidden = [n layers * n directions, batch size, hid dim]\n",
        "    # cell = [n layer * n directions, batch size, hid dim]\n",
        "\n",
        "    # outputs = [src len, batch size, hid dim * n directions]\n",
        "    ## outputì€ ì–¸ì œë‚˜ hidden layerì˜ topì— ìˆìŒ\n",
        "\n",
        "    return hidden, cell"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RItpYm8jzzj"
      },
      "source": [
        "### Decoder\n",
        "- decoderë„ encoderì™€ ë§ˆì°¬ê°€ì§€ë¡œ 2ê°œì˜ LSTM layerë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. (ë…¼ë¬¸ì—ì„œëŠ” 4ê°œì˜ layerë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.)\n",
        "  ![](/images/seq2seq3.png)\n",
        "\n",
        "- ë‹¤ìŒì€ Decoderì˜ layerë¥¼ ìˆ˜ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚¸ ì‹ì…ë‹ˆë‹¤.\n",
        "\n",
        "  $(s_t^1, c_t^1) = \\text{DecoderLSTM}^1(d(y_t), (s_{t-1}^1, c_{t-1}^1))\\\\\n",
        "  (s_t^2, c_t^2) = \\text{DecoderLSTM}^2(s_t^1, (s_{t-1}^2, c_{t-1}^2))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_ZanUngHECa"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "        # input = [batch size]\n",
        "        ## í•œë²ˆì— í•˜ë‚˜ì˜ tokenë§Œ decodingí•˜ë¯€ë¡œ forwardì—ì„œì˜ input tokenì˜ ê¸¸ì´ëŠ” 1ì…ë‹ˆë‹¤.\n",
        "        \n",
        "        # hidden = [n layers * n directions, batch size, hid dim]\n",
        "        # cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        # n directions in the decoder will both always be 1, therefore:\n",
        "        # hidden = [n layers, batch size, hid dim]\n",
        "        # context = [n layers, batch size, hid dim]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        # inputì„ 0ì°¨ì›ì— ëŒ€í•´ unsqueezeí•´ì„œ 1ì˜ sentence length dimensionì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "        # input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        # embedding layerë¥¼ í†µê³¼í•œ í›„ì— dropoutì„ í•©ë‹ˆë‹¤.\n",
        "        # embedded = [1, batch size, emb dim]\n",
        "                \n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        \n",
        "        # output = [seq len, batch size, hid dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, hid dim]\n",
        "        # cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        # seq len and n directions will always be 1 in the decoder, therefore:\n",
        "        # output = [1, batch size, hid dim]\n",
        "        # hidden = [n layers, batch size, hid dim]\n",
        "        # cell = [n layers, batch size, hid dim]\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden, cell"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfGRH6zVLvk6"
      },
      "source": [
        "## Seq2Seq\n",
        "\n",
        "![](/images/seq2seq4.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybFYGRt5I2hB"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jB9OpTrI3L-"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-58y-hbI_aS",
        "outputId": "a83c7e5d-35ec-4d93-ca72-a1fde228700a"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(7855, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(5893, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ypW8ITHI5HC",
        "outputId": "1ccbdffa-69c0-4582-b0ec-611b79125964"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 13,899,013 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvnbqQPTMJ1K"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QZl4LTYMK6m"
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itnpa_9XMK9Z"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efcpaqOtMK_V"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAVjT1R-MLBz"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3gyumXIMT9S",
        "outputId": "1391dac8-bef5-4fa4-8bdd-16ad50dd58a3"
      },
      "source": [
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 38s\n",
            "\tTrain Loss: 5.052 | Train PPL: 156.330\n",
            "\t Val. Loss: 5.009 |  Val. PPL: 149.767\n",
            "Epoch: 02 | Time: 0m 37s\n",
            "\tTrain Loss: 4.483 | Train PPL:  88.471\n",
            "\t Val. Loss: 4.817 |  Val. PPL: 123.627\n",
            "Epoch: 03 | Time: 0m 37s\n",
            "\tTrain Loss: 4.193 | Train PPL:  66.237\n",
            "\t Val. Loss: 4.675 |  Val. PPL: 107.187\n",
            "Epoch: 04 | Time: 0m 37s\n",
            "\tTrain Loss: 4.006 | Train PPL:  54.940\n",
            "\t Val. Loss: 4.543 |  Val. PPL:  93.994\n",
            "Epoch: 05 | Time: 0m 37s\n",
            "\tTrain Loss: 3.853 | Train PPL:  47.152\n",
            "\t Val. Loss: 4.419 |  Val. PPL:  83.004\n",
            "Epoch: 06 | Time: 0m 37s\n",
            "\tTrain Loss: 3.717 | Train PPL:  41.151\n",
            "\t Val. Loss: 4.419 |  Val. PPL:  83.041\n",
            "Epoch: 07 | Time: 0m 37s\n",
            "\tTrain Loss: 3.598 | Train PPL:  36.537\n",
            "\t Val. Loss: 4.235 |  Val. PPL:  69.030\n",
            "Epoch: 08 | Time: 0m 37s\n",
            "\tTrain Loss: 3.462 | Train PPL:  31.871\n",
            "\t Val. Loss: 4.120 |  Val. PPL:  61.552\n",
            "Epoch: 09 | Time: 0m 37s\n",
            "\tTrain Loss: 3.339 | Train PPL:  28.205\n",
            "\t Val. Loss: 4.060 |  Val. PPL:  57.994\n",
            "Epoch: 10 | Time: 0m 37s\n",
            "\tTrain Loss: 3.212 | Train PPL:  24.839\n",
            "\t Val. Loss: 4.076 |  Val. PPL:  58.898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzt3w5UbMT_s"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSJh-E8WMUD6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jPNHnJKMUFY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcRwnBb6MLHI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}