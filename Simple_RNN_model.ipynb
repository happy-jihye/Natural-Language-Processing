{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_RNN_model.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM65Oo4c/yu8aXBz1K/Pe17",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/happy-jihye/Natural-Language-Processing/blob/main/Simple_RNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26nADTPFDL6F"
      },
      "source": [
        "# Simple RNN model\r\n",
        "\r\n",
        "- Pytorch / TorchText\r\n",
        "- RNN network를 사용한 간단한 Sentiment Analysis 예제\r\n",
        "> - 2021/03/21 Happy-jihye\r\n",
        "> - **Reference** : [pytorch-sentiment-analysis/1 - Simple Sentiment Analysis](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0jFZX0dEmMB"
      },
      "source": [
        "## 1. Preparing Data\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFd2lRS-G89C"
      },
      "source": [
        "#### 1) Text/Label\r\n",
        "- **[spaCy](https://spacy.io/)** : nlp를 쉽게 할 수 있도록 도와주는 파이썬 패키지로, tokenizaing, parsing, pos tagging 등을 지원\r\n",
        "- **[Field](https://pytorch.org/text/_modules/torchtext/data/field.html)** 에 정의된 내용을 기반으로 영어를 token화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Lj415BkW090",
        "outputId": "328b328e-0719-44eb-db5a-e2e33ef4d4dc"
      },
      "source": [
        "!apt install python3.7"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3.7 is already the newest version (3.7.10-1+bionic2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0cr1n7oE-pM",
        "outputId": "71f17b70-aaf0-4a9a-9255-fcb171b20b11"
      },
      "source": [
        "!pip install -U torchtext==0.6.0"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torchtext==0.6.0 in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.8.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (0.1.95)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cArSLZmKEydH"
      },
      "source": [
        "%%capture\r\n",
        "!python -m spacy download en"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn9QsVChE48-"
      },
      "source": [
        "import torch\r\n",
        "from torchtext import data\r\n",
        "\r\n",
        "TEXT = data.Field(tokenize = 'spacy',\r\n",
        "                  tokenizer_language = 'en')\r\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R9bRwoyIia9"
      },
      "source": [
        "#### 2) IMDb Dataset\r\n",
        "- 5만개의 영화 리뷰로 구성된 IMDB dataset을 다운로드 받은 후, 이전에 정의한 Field를 사용해서 데이터를 처리(TEXT, LABEL)\r\n",
        "- torchtext.datasets 의 [IMDB](https://pytorch.org/text/stable/datasets.html#imdb) 객체로 train data와 test data을 split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PadXXIFIKXg_"
      },
      "source": [
        "from torchtext import datasets\r\n",
        "\r\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXkUEhDjK-zn",
        "outputId": "cea17a97-0756-4f5c-f013-54df9674e8ca"
      },
      "source": [
        "print(f'training examples 수 : {len(train_data)}')\r\n",
        "print(f'testing examples 수 : {len(test_data)}')\r\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training examples 수 : 25000\n",
            "testing examples 수 : 25000\n",
            "{'text': ['Anyone', 'new', 'to', 'the', 'incredibly', 'prolific', 'Takashi', 'Miike', \"'s\", 'work', 'might', 'want', 'to', 'think', 'twice', 'about', 'making', 'this', 'startling', 'film', 'their', 'first', 'experience', 'of', 'this', 'truly', 'maverick', 'director', '.', 'In', 'keeping', 'with', 'Miike', \"'s\", 'working', 'practice', 'of', 'taking', 'any', 'work', 'that', 'comes', 'his', 'way', 'and', 'then', 'grafting', 'his', 'own', 'sensibilities', 'onto', 'the', 'script', ',', 'this', 'is', 'at', 'heart', 'a', 'fairly', 'basic', 'yakuza', 'thriller', ',', 'with', 'a', 'morally', 'ambiguous', 'cop', 'chasing', 'a', 'gang', 'which', 'his', 'lawyer', 'brother', 'has', 'fallen', 'in', 'with', '.', 'What', 'takes', 'the', 'movie', 'out', 'of', 'the', 'realms', 'of', 'the', 'same', '-', 'old', 'same', '-', 'old', 'however', ',', 'is', 'the', 'utterly', 'unflinching', 'attitude', 'so', 'some', 'of', 'the', 'most', 'sudden', 'and', 'horrific', 'violence', 'seen', 'in', 'today', \"'s\", 'cinema', '.', 'And', 'this', 'is', \"n't\", 'that', 'nice', 'cool', ',', 'clean', 'violence', 'so', 'beloved', 'of', 'US', 'cinema', '-', 'this', 'stuff', 'is', 'nasty', ',', 'painful', 'and', 'HURTS', '!', 'That', 'said', ',', 'the', 'pace', 'is', 'breakneck', ',', 'the', 'characters', 'are', 'unusual', 'without', 'being', 'just', 'being', 'burdened', 'with', 'stock', 'eccentricities', ',', 'Miike', \"'s\", 'sense', 'of', 'humour', 'reveals', 'itself', 'and', 'the', 'most', 'unexpected', 'moments', ',', 'and', 'his', 'camera', 'is', 'never', 'quite', 'where', 'you', 'expect', 'it', 'to', 'be', ',', 'making', 'it', 'hard', 'to', 'look', 'away', 'from', 'the', 'screen', ',', 'whatever', 'he', 'might', 'be', 'showing', 'you', '!', 'It', 'does', \"n't\", 'have', 'the', '\"', 'Ohmigod', '\"', 'ending', 'of', '\"', 'Dead', 'Or', 'Alive', ',', '\"', 'but', 'if', 'you', \"'re\", 'not', 'squeamish', ',', 'now', \"'s\", 'the', 'time', 'to', 'get', 'on', 'board', 'the', 'Miike', 'bandwagon', 'before', 'he', 'ends', 'up', 'on', 'some', 'Hollywood', 'studio', \"'s\", '\"', 'new', 'John', 'Woo', '\"', 'shopping', 'list', '...'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YULs86qbL4L9"
      },
      "source": [
        "- IMDb dataset은 train/test data만 있고, validation set이 없음\r\n",
        "\r\n",
        "  따라서 train dataset을 split해서 validation dataset 을 만들기!!\r\n",
        "  (split 함수의 default split_ratio = 0.7)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9-dgz-PMQp6"
      },
      "source": [
        "import random\r\n",
        "\r\n",
        "SEED = 1234\r\n",
        "\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True\r\n",
        "\r\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK61YhDIMgPm",
        "outputId": "f597958d-d2c7-46ec-b9a0-dadf93578b27"
      },
      "source": [
        "print(f'training examples 수 : {len(train_data)}')\r\n",
        "print(f'validations examples 수 : {len(valid_data)}')\r\n",
        "print(f'testing examples 수 : {len(test_data)}')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training examples 수 : 17500\n",
            "validations examples 수 : 7500\n",
            "testing examples 수 : 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMQDknQkNKGY"
      },
      "source": [
        "#### 3) Build Vocabulary\r\n",
        "- one-hot encoding 방식을 사용해서 단어들을 indexing 함\r\n",
        "![](images/Simple_RNN_model1.png)\r\n",
        "\r\n",
        "\r\n",
        "- training dataset에 있는 단어들은 10만개가 넘는데, 이 모든 단어들에 대해 indexing을 하면 one-hot vector의 dimension이 10만개가 되므로 연산하기 좋지 않음\r\n",
        "  - 따라서 어휘의 수를 MAX_VOCAB_SIZE로 제한\r\n",
        "  (이 예제에서는 **25,000 words**를 사용)\r\n",
        "  - ex) \"This film is great and I love it\" 라는 문장에서 \"love\"라는 단어가 vocabulary에 없다면, \"This film is great and I $<unk>$ it\"로 문장을 학습시키게 됨\r\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8r09NpIPPXH"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\r\n",
        "\r\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE, min_freq = 5)\r\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty-HvZnzR2MB"
      },
      "source": [
        "- vocab size가 25,000개가 아닌 25,002개인 이유는 $<unk>$ token과 $<pad>$ token이 추가되었기 때문\r\n",
        "- $<pad>$ token : 문장의 길이를 맞추기 위해 있는 token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnRLbdsMRKLX",
        "outputId": "6f5dcca4-6c97-4acf-ee72-8bad661f8f2d"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\r\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMCUWH1YSHnv",
        "outputId": "e922bb76-84f4-4f25-a5a4-24e71ad5e7da"
      },
      "source": [
        "print(f\"가장 자주 나오는 단어들 20개 출력 :\\n{TEXT.vocab.freqs.most_common(20)}\\n\")\r\n",
        "\r\n",
        "# itos(int to string)\r\n",
        "print(TEXT.vocab.itos[:5])\r\n",
        "\r\n",
        "# stoi(string to int)\r\n",
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "가장 자주 나오는 단어들 20개 출력 :\n",
            "[('the', 204412), (',', 192936), ('.', 166941), ('a', 110304), ('and', 109590), ('of', 101675), ('to', 94170), ('is', 76946), ('in', 61671), ('I', 54581), ('it', 53843), ('that', 49317), ('\"', 44555), (\"'s\", 43644), ('this', 42548), ('-', 37200), ('/><br', 35695), ('was', 35052), ('as', 30433), ('with', 30218)]\n",
            "\n",
            "['<unk>', '<pad>', 'the', ',', '.']\n",
            "defaultdict(None, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVSBULSUSUjW"
      },
      "source": [
        "#### 4) Iterator\r\n",
        "\r\n",
        "- GPU를 사용할 수 있다면 GPU 사용 (colab이라면 런타임 유형을 GPU로 설정하기)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm0iCra-aEk0",
        "outputId": "c91ec806-f49f-4002-d209-214b1bca220f"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwJS7CKZT6jc"
      },
      "source": [
        "import torch\r\n",
        "\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QucJLf94s9-q"
      },
      "source": [
        "- BucketIterator를 사용하여 interators를 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khgb9NUFYXXI"
      },
      "source": [
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\r\n",
        "    (train_data, valid_data, test_data),\r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    device = device\r\n",
        ")"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NfL5WwTn7Fp",
        "outputId": "b49d553c-87df-4caf-d638-e3056993f01f"
      },
      "source": [
        "# iterator 출력\r\n",
        "for i, batch in enumerate(train_iterator):\r\n",
        "    text = batch.text\r\n",
        "    label = batch.label\r\n",
        "\r\n",
        "    print(f\"첫 번째 배치의 text 크기: {text.shape}\")\r\n",
        "    print(text[3])\r\n",
        "    print(text[3].shape)\r\n",
        "    print(f\"첫 번째 배치의 label 크기: {label.shape}\")\r\n",
        "    print(label)\r\n",
        "\r\n",
        "    # 첫 번째 batch만 출력\r\n",
        "    break"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "첫 번째 배치의 text 크기: torch.Size([1411, 64])\n",
            "tensor([   35,    11,  2570,   305,   458,   448,   658,     8, 10220,     3,\n",
            "          494,   127,   303,    83,   277,    22,   541,    80,   390,    80,\n",
            "         3599,   166,  1302,     4,    80,   178,    65,    24,     7,    16,\n",
            "          311,   465,   827,    83,    19,   168,   805,    16,   478,   409,\n",
            "            6,    10,     5,    16,   182,    22,     5,  1804,    15,    21,\n",
            "          490,     8,   832,    22,   264,    65,   137,   173,     7,  7289,\n",
            "          103,     5,    38,    23], device='cuda:0')\n",
            "torch.Size([64])\n",
            "첫 번째 배치의 label 크기: torch.Size([64])\n",
            "tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
            "        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
            "        1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
            "        1., 0., 1., 1., 0., 1., 0., 1., 1., 0.], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBtU7KsqZ12O"
      },
      "source": [
        "## 2. Build Model\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-j7VO8ayts"
      },
      "source": [
        "**Embedding layer**\r\n",
        "![](images/Simple_RNN_model3.png)\r\n",
        "- [Embedding layer](https://wikidocs.net/64779) : input을 dense vector(embedding vector)로 mapping 해주는 일종의 look-up table\r\n",
        "  - 이때, 이 dense vector는 인공 신경망의 학습과정에서 가중치가 학습되는 것과 같은 방식으로 훈련됨. (역전파 과정에서 embedding vector값이 학습됨)\r\n",
        "  - pytorch에서는 단어를 정수 index로 바꾸고 one-hot vector로 한번 더 바꾸고 나서 embedding layer의 입력으로 사용하는 것이 아니라, 단어를 정수 index로만 바꾼 채로 embedding layer의 입력으로 사용해도 look-up table의 결과인 embedding vector를 return함.\r\n",
        "  - [Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMiDiSqofOZ0"
      },
      "source": [
        "**RNN Layer**\r\n",
        "- 이 model은 RNN layer를 사용\r\n",
        "- RNN은 문장($X=\\{x_1, ..., x_T\\}$)속 단어들을 한번에 하나씩 계산하여 각 단어당 *hidden state*(h)를 구함\r\n",
        "- 이전 hidden state $h_{t-1}$와 가지고 있는 dense vector를 이용하여 다음 hidden state인 $h_{t}$ 를 계산\r\n",
        "$$h_t = \\text{RNN}(x_t, h_{t-1})$$\r\n",
        "\r\n",
        "  ![](images/Simple_RNN_model2.png)\r\n",
        "- final hidden state인 $h_T$를 linear layer에 통과시킴으로써 prediction 결과를 얻음 ($\\hat{y} = f(h_T)$)\r\n",
        "\r\n",
        "- 이 예제에서는 부정적인 감정을 가지면 0을 예측하도록 RNN을 학습시킴\r\n",
        "  ![](images/Simple_RNN_model4.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v8A8X6CbeuJ"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "\r\n",
        "class RNN(nn.Module):\r\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim)\r\n",
        "    self.rnn = nn.RNN(embedding_dim, hidden_dim)\r\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\r\n",
        "  \r\n",
        "  def forward(self, text):\r\n",
        "    \r\n",
        "    # text = [sentence length, batch size]\r\n",
        "\r\n",
        "    embedded = self.embedding(text)\r\n",
        "\r\n",
        "    # embedded = [sentence length, batch size, embedding dim]\r\n",
        "\r\n",
        "    output, hidden = self.rnn(embedded)\r\n",
        "\r\n",
        "    # output = [sentence length, batch size, hidden dim]\r\n",
        "    # hidden = [1, batch size, hidden dim]\r\n",
        "\r\n",
        "    return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ui0Y4b0g1ax"
      },
      "source": [
        "- **Input dim** : one-hot vector의 dimension과 같음(vocabulary size)\r\n",
        "- **Embedding dim** : 보통 50-250 dimensions\r\n",
        "- **Hidden dim** :보통 100-500 dim\r\n",
        "- **Output dim** : class의 수, 위 예제에서는 0아니면 1이므로 1-dim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN_0DpCqgQNx"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab) #25,002\r\n",
        "EMBEDDING_DIM = 100\r\n",
        "HIDDEN_DIM = 256\r\n",
        "OUTPUT_DIM = 1\r\n",
        "\r\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6uSeSNhhdju",
        "outputId": "f84a2542-5320-4780-88b9-e0b44769e77c"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,592,105 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy-6lg_HhfSb"
      },
      "source": [
        "## 3. Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtXPbSXchiIy"
      },
      "source": [
        "#### optimizer\r\n",
        "- **stochastic gradient descent (SGD)** 를 이용해서 model을 업데이트할 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0vLv4drhyXL"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "\r\n",
        "optimizer =optim.SGD(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XxWUCDih_0z"
      },
      "source": [
        "#### loss function\r\n",
        "- loss function 은 **binary cross entropy with logits**\r\n",
        "- 0아니면 1의 label을 예측해야하므로 **sigmoid**나 **logit** function을 사용\r\n",
        "- [BCEWithLogitsLoss](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)는 sigmoid와 the binary cross entropy steps를 모두 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A9f5ysXikuR"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjQocNIZip3B"
      },
      "source": [
        "- GPU 사용이 가능하도록"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZosE0TCpis_9"
      },
      "source": [
        "model = model.to(device)\r\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w4aPDkeixl_"
      },
      "source": [
        "**accuracy function**\r\n",
        "- sigmoid layer를 지나면 0과 1사이의 값이 나오는데, 우리가 필요한 값은 0,1의 label이므로 [nn.round](https://pytorch.org/docs/stable/generated/torch.round.html)를 이용하여 반올림하기\r\n",
        "- prediction 값과 label 값이 같은 것들이 얼마나 있는지를 계산하여 정확도를 측정하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruGAS62rjQoy"
      },
      "source": [
        "def binary_accuracy(preds, y):\r\n",
        "\r\n",
        "  rounded_preds = torch.round(torch.sigmoid(preds))\r\n",
        "  # rounded_preds : [batch size]\r\n",
        "  # y : batch.label\r\n",
        "  correct = (rounded_preds == y).float()\r\n",
        "  acc = correct.sum() / len(correct)\r\n",
        "  return acc"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-Y-o_4kjkw2"
      },
      "source": [
        "### 1) Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLVdffp-jojk"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\r\n",
        "\r\n",
        "  epoch_loss = 0\r\n",
        "  epoch_acc = 0\r\n",
        "\r\n",
        "  # model을 \"training mode\"로 -> dropout이나 batch normalization이 가능해짐\r\n",
        "  # 이 모델에서는 이를 사용하지는 않음\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  for batch in iterator:\r\n",
        "\r\n",
        "    # 모든 batch마다 gradient를 0으로 초기화\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    # batch of sentences인 batch.text를 model에 입력 (저절로 forward가 됨)\r\n",
        "    # predictions의 크기가 [batch size, 1]이므로 squeeze해서 [batch size]로 size를 변경해줘야 함 \r\n",
        "    predictions = model(batch.text).squeeze(1)\r\n",
        "\r\n",
        "    # prediction결과와 batch.label을 비교하여 loss값 계산 \r\n",
        "    loss = criterion(predictions, batch.label)\r\n",
        "\r\n",
        "    # 정확도 계산\r\n",
        "    acc = binary_accuracy(predictions, batch.label)\r\n",
        "\r\n",
        "    # backward()를 사용하여 역전파 수행\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    # 최적화 알고리즘을 사용하여 parameter를 update\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    epoch_loss += loss.item()\r\n",
        "    epoch_acc += acc.item()\r\n",
        "\r\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7aRqf7Cl9pu"
      },
      "source": [
        "### 2) Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBP2c1Q0mCXp"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "  epoch_loss = 0\r\n",
        "  epoch_acc = 0\r\n",
        "\r\n",
        "  # \"evaluation mode\" : dropout이나 batch nomalizaation을 끔\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  # pytorch에서 gradient가 계산되지 않도록 해서 memory를 적게 쓰고 computation 속도를 높임\r\n",
        "  with torch.no_grad():\r\n",
        "    \r\n",
        "    for batch in iterator :\r\n",
        "      predictions = model(batch.text).squeeze(1)\r\n",
        "      \r\n",
        "      loss = criterion(predictions, batch.label)\r\n",
        "      acc = binary_accuracy(predictions, batch.label)\r\n",
        "\r\n",
        "      epoch_loss += loss.item()\r\n",
        "      epoch_acc += acc.item()\r\n",
        "\r\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wt3HQYEp3b2"
      },
      "source": [
        "- epoch 시간을 계산하기 위한 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erTMajygmvuo"
      },
      "source": [
        "import time\r\n",
        "\r\n",
        "def epoch_time(start_time, end_time):\r\n",
        "  elapsed_time = end_time - start_time\r\n",
        "  elapsed_mins = int(elapsed_time / 60)\r\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTZ9k2EhvO_6"
      },
      "source": [
        "### Train the model through multiple epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGrnQs4FnHtE",
        "outputId": "6e0c2d63-1ea8-4f79-a350-e90a89986b32"
      },
      "source": [
        "N_EPOCHS = 5\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "\r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\r\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "\r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 0.694 | Train Acc: 49.82%\n",
            "\t Val. Loss: 0.695 |  Val. Acc: 50.19%\n",
            "Epoch: 02 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.41%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 50.51%\n",
            "Epoch: 03 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.11%\n",
            "\t Val. Loss: 0.695 |  Val. Acc: 50.54%\n",
            "Epoch: 04 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.22%\n",
            "\t Val. Loss: 0.695 |  Val. Acc: 50.19%\n",
            "Epoch: 05 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.58%\n",
            "\t Val. Loss: 0.695 |  Val. Acc: 50.05%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfCNhdYznr5l",
        "outputId": "049e791a-dffd-4112-ffcd-72b279b48031"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\r\n",
        "\r\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\r\n",
        "\r\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\r\n"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.710 | Test Acc: 46.36%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}